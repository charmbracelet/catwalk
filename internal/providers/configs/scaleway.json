{
  "name": "Scaleway",
  "id": "scaleway",
  "api_key": "$SCALEWAY_API_KEY",
  "api_endpoint": "https://api.scaleway.ai/v1",
  "type": "openai",
  "default_large_model_id": "qwen3-235b-a22b-instruct-2507",
  "default_small_model_id": "llama-3.1-8b-instruct",
  "models": [
    {
      "id": "qwen3-235b-a22b-instruct-2507",
      "name": "Qwen3-235B-A22B-Instruct-2507",
      "cost_per_1m_in": 0.75,
      "cost_per_1m_out": 2.25,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 260000,
      "default_max_tokens": 8192,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "gpt-oss-120b",
      "name": "GPT-OSS-120B",
      "cost_per_1m_in": 0.15,
      "cost_per_1m_out": 0.6,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 8192,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "gemma-3-27b-it",
      "name": "Gemma-3-27B-IT",
      "cost_per_1m_in": 0.25,
      "cost_per_1m_out": 0.5,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 40000,
      "default_max_tokens": 8192,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": true
    },
    {
      "id": "voxtral-small-24b-2507",
      "name": "Voxtral-Small-24B-2507",
      "cost_per_1m_in": 0.15,
      "cost_per_1m_out": 0.35,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 32000,
      "default_max_tokens": 8192,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "mistral-small-3.2-24b-instruct-2506",
      "name": "Mistral-Small-3.2-24B-Instruct-2506",
      "cost_per_1m_in": 0.15,
      "cost_per_1m_out": 0.35,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 8192,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": true
    },
    {
      "id": "llama-3.3-70b-instruct",
      "name": "Llama-3.3-70B-Instruct",
      "cost_per_1m_in": 0.9,
      "cost_per_1m_out": 0.9,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 4096,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "deepseek-r1-distill-llama-70b",
      "name": "Deepseek-R1-Distill-Llama-70B",
      "cost_per_1m_in": 0.9,
      "cost_per_1m_out": 0.9,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 32768,
      "default_max_tokens": 4096,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct",
      "name": "Qwen3-Coder-30B-A3B-Instruct",
      "cost_per_1m_in": 0.2,
      "cost_per_1m_out": 0.8,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 8192,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "pixtral-12b-2409",
      "name": "Pixtral-12B-2409",
      "cost_per_1m_in": 0.2,
      "cost_per_1m_out": 0.2,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 4096,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": true
    },
    {
      "id": "mistral-nemo-instruct-2407",
      "name": "Mistral-Nemo-Instruct-2407",
      "cost_per_1m_in": 0.2,
      "cost_per_1m_out": 0.2,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 8192,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "llama-3.1-8b-instruct",
      "name": "Llama-3.1-8B-Instruct",
      "cost_per_1m_in": 0.2,
      "cost_per_1m_out": 0.2,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 16384,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "qwen2.5-coder-32b-instruct",
      "name": "Qwen2.5-Coder-32B-Instruct",
      "cost_per_1m_in": 0.9,
      "cost_per_1m_out": 0.9,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 32000,
      "default_max_tokens": 8192,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    },
    {
      "id": "llama-3.1-70b-instruct",
      "name": "Llama-3.1-70B-Instruct",
      "cost_per_1m_in": 0.9,
      "cost_per_1m_out": 0.9,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 4096,
      "can_reason": false,
      "has_reasoning_efforts": false,
      "supports_attachments": false
    }
  ]
}