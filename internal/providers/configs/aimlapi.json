{
  "name": "AI/ML API",
  "id": "aimlapi",
  "api_key": "$AIMLAPI_API_KEY",
  "api_endpoint": "https://api.aimlapi.com/v1",
  "type": "openai-compat",
  "default_large_model_id": "openai/gpt-5-chat-latest",
  "default_small_model_id": "deepseek/deepseek-chat-v3.1",
  "models": [
    {
      "id": "deepseek/deepseek-chat-v3.1",
      "name": "DeepSeek V3.1",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 8000,
      "can_reason": true,
      "supports_attachments": true,
      "options": {}
    },
    {
      "id": "openai/gpt-5-chat-latest",
      "name": "GPT-5 Chat Latest",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 400000,
      "default_max_tokens": 16384,
      "can_reason": true,
      "supports_attachments": true,
      "options": {}
    },
    {
      "id": "deepseek/deepseek-reasoner-v3.1",
      "name": "DeepSeek Reasoner V3.1",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 64000,
      "can_reason": true,
      "supports_attachments": true,
      "options": {}
    },
    {
      "id": "openai/gpt-4o",
      "name": "GPT 4o",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 16384,
      "can_reason": true,
      "supports_attachments": true,
      "options": {}
    },
    {
      "id": "gpt-4o-mini",
      "name": "GPT 4o mini",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 16384,
      "can_reason": true,
      "supports_attachments": true,
      "options": {}
    },
    {
      "id": "google/gemini-2.0-flash-exp",
      "name": "Gemini 2.0 Flash Experimental",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 1000000,
      "default_max_tokens": 8192,
      "can_reason": true,
      "supports_attachments": true,
      "options": {}
    },
    {
      "id": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
      "name": "Meta Llama 3.1 70B Instruct Turbo",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 127000,
      "can_reason": true,
      "supports_attachments": false,
      "options": {}
    },
    {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
      "name": "Meta Llama 3.1 8B Instruct Turbo",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 128000,
      "default_max_tokens": 127000,
      "can_reason": true,
      "supports_attachments": false,
      "options": {}
    },
    {
      "id": "Qwen/Qwen2.5-72B-Instruct-Turbo",
      "name": "Qwen2.5 72B Instruct Turbo",
      "cost_per_1m_in": 0,
      "cost_per_1m_out": 0,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 32000,
      "default_max_tokens": 31000,
      "can_reason": true,
      "supports_attachments": false,
      "options": {}
    }
  ]
}
