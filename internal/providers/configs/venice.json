{
  "name": "Venice AI",
  "id": "venice",
  "type": "openai",
  "api_key": "$VENICE_API_KEY",
  "api_endpoint": "https://api.venice.ai/api/v1",
  "default_large_model_id": "qwen3-235b",
  "default_small_model_id": "mistral-31-24b",
  "models": [
    {
      "id": "qwen3-235b",
      "name": "Venice Large",
      "cost_per_1m_in": 1.5,
      "cost_per_1m_out": 6,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 50000,
      "can_reason": true,
      "supports_attachments": false
    },
    {
      "id": "qwen3-4b",
      "name": "Venice Small",
      "cost_per_1m_in": 0.15,
      "cost_per_1m_out": 0.6,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 32768,
      "default_max_tokens": 25000,
      "can_reason": true,
      "supports_attachments": false
    },
    {
      "id": "mistral-31-24b",
      "name": "Venice Medium",
      "cost_per_1m_in": 0.5,
      "cost_per_1m_out": 2,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 50000,
      "can_reason": false,
      "supports_attachments": true
    },
    {
      "id": "llama-3.2-3b",
      "name": "Llama 3.2 3B",
      "cost_per_1m_in": 0.15,
      "cost_per_1m_out": 0.6,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 25000,
      "can_reason": false,
      "supports_attachments": false
    },
    {
      "id": "llama-3.3-70b",
      "name": "Llama 3.3 70B",
      "cost_per_1m_in": 0.7,
      "cost_per_1m_out": 2.8,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 65536,
      "default_max_tokens": 32000,
      "can_reason": false,
      "supports_attachments": false
    }
  ]
}
