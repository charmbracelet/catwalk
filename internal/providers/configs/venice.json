{
  "name": "Venice AI",
  "id": "venice",
  "api_key": "$VENICE_API_KEY",
  "api_endpoint": "https://api.venice.ai/api/v1",
  "type": "openai-compat",
  "default_large_model_id": "openai-gpt-52",
  "default_small_model_id": "qwen3-4b",
  "models": [
    {
      "id": "claude-opus-45",
      "name": "Claude Opus 4.5",
      "cost_per_1m_in": 6,
      "cost_per_1m_out": 30,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 202752,
      "default_max_tokens": 32768,
      "can_reason": true,
      "reasoning_levels": [
        "low",
        "medium",
        "high"
      ],
      "default_reasoning_effort": "medium",
      "supports_attachments": true,
      "options": {
        "temperature": 0.7,
        "top_p": 0.9
      }
    },
    {
      "id": "zai-org-glm-4.6",
      "name": "GLM 4.6",
      "cost_per_1m_in": 0.85,
      "cost_per_1m_out": 2.75,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 202752,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": false,
      "options": {
        "temperature": 0.7,
        "top_p": 0.9
      }
    },
    {
      "id": "zai-org-glm-4.6v",
      "name": "GLM 4.6V",
      "cost_per_1m_in": 0.39,
      "cost_per_1m_out": 1.13,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": true,
      "options": {
        "temperature": 0.8,
        "top_p": 0.6
      }
    },
    {
      "id": "zai-org-glm-4.7",
      "name": "GLM 4.7",
      "cost_per_1m_in": 0.85,
      "cost_per_1m_out": 2.75,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": false,
      "options": {
        "temperature": 1,
        "top_p": 0.95
      }
    },
    {
      "id": "openai-gpt-52",
      "name": "GPT-5.2",
      "cost_per_1m_in": 2.19,
      "cost_per_1m_out": 17.5,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 262144,
      "default_max_tokens": 32768,
      "can_reason": true,
      "reasoning_levels": [
        "low",
        "medium",
        "high"
      ],
      "default_reasoning_effort": "medium",
      "supports_attachments": false,
      "options": {
        "temperature": 0.7,
        "top_p": 0.9
      }
    },
    {
      "id": "gemini-3-flash-preview",
      "name": "Gemini 3 Flash Preview",
      "cost_per_1m_in": 0.7,
      "cost_per_1m_out": 3.75,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 262144,
      "default_max_tokens": 32768,
      "can_reason": true,
      "reasoning_levels": [
        "low",
        "medium",
        "high"
      ],
      "default_reasoning_effort": "medium",
      "supports_attachments": true,
      "options": {
        "temperature": 1,
        "top_p": 0.95
      }
    },
    {
      "id": "gemini-3-pro-preview",
      "name": "Gemini 3 Pro Preview",
      "cost_per_1m_in": 2.5,
      "cost_per_1m_out": 15,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 202752,
      "default_max_tokens": 32768,
      "can_reason": true,
      "reasoning_levels": [
        "low",
        "medium",
        "high"
      ],
      "default_reasoning_effort": "medium",
      "supports_attachments": true,
      "options": {
        "temperature": 0.7,
        "top_p": 0.8
      }
    },
    {
      "id": "google-gemma-3-27b-it",
      "name": "Google Gemma 3 27B Instruct",
      "cost_per_1m_in": 0.12,
      "cost_per_1m_out": 0.2,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 202752,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": true,
      "options": {
        "temperature": 0.7,
        "top_p": 0.9
      }
    },
    {
      "id": "grok-41-fast",
      "name": "Grok 4.1 Fast",
      "cost_per_1m_in": 0.5,
      "cost_per_1m_out": 1.25,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 262144,
      "default_max_tokens": 32768,
      "can_reason": true,
      "reasoning_levels": [
        "low",
        "medium",
        "high"
      ],
      "default_reasoning_effort": "medium",
      "supports_attachments": true,
      "options": {
        "temperature": 0.7,
        "top_p": 0.8
      }
    },
    {
      "id": "kimi-k2-thinking",
      "name": "Kimi K2 Thinking",
      "cost_per_1m_in": 0.75,
      "cost_per_1m_out": 3.2,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 262144,
      "default_max_tokens": 32768,
      "can_reason": true,
      "reasoning_levels": [
        "low",
        "medium",
        "high"
      ],
      "default_reasoning_effort": "medium",
      "supports_attachments": false,
      "options": {
        "temperature": 0.7,
        "top_p": 0.8
      }
    },
    {
      "id": "llama-3.2-3b",
      "name": "Llama 3.2 3B",
      "cost_per_1m_in": 0.15,
      "cost_per_1m_out": 0.6,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": false,
      "options": {
        "temperature": 0.6,
        "top_p": 0.95
      }
    },
    {
      "id": "llama-3.3-70b",
      "name": "Llama 3.3 70B",
      "cost_per_1m_in": 0.7,
      "cost_per_1m_out": 2.8,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": false,
      "options": {
        "temperature": 0.6,
        "top_p": 0.95
      }
    },
    {
      "id": "openai-gpt-oss-120b",
      "name": "OpenAI GPT OSS 120B",
      "cost_per_1m_in": 0.07,
      "cost_per_1m_out": 0.3,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": false,
      "options": {
        "temperature": 0.7,
        "top_p": 0.9
      }
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507",
      "name": "Qwen 3 235B A22B Instruct 2507",
      "cost_per_1m_in": 0.15,
      "cost_per_1m_out": 0.75,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": false,
      "options": {
        "temperature": 0.7,
        "top_p": 0.8
      }
    },
    {
      "id": "qwen3-235b-a22b-thinking-2507",
      "name": "Qwen 3 235B A22B Thinking 2507",
      "cost_per_1m_in": 0.45,
      "cost_per_1m_out": 3.5,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 32768,
      "can_reason": true,
      "reasoning_levels": [
        "low",
        "medium",
        "high"
      ],
      "default_reasoning_effort": "medium",
      "supports_attachments": false,
      "options": {
        "temperature": 0.6,
        "top_p": 0.95
      }
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct",
      "name": "Qwen 3 Coder 480b",
      "cost_per_1m_in": 0.75,
      "cost_per_1m_out": 3,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 262144,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": false,
      "options": {
        "temperature": 0.7,
        "top_p": 0.8
      }
    },
    {
      "id": "qwen3-next-80b",
      "name": "Qwen 3 Next 80b",
      "cost_per_1m_in": 0.35,
      "cost_per_1m_out": 1.9,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 262144,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": false,
      "options": {
        "temperature": 0.7,
        "top_p": 0.8
      }
    },
    {
      "id": "mistral-31-24b",
      "name": "Venice Medium",
      "cost_per_1m_in": 0.5,
      "cost_per_1m_out": 2,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 131072,
      "default_max_tokens": 32768,
      "can_reason": false,
      "supports_attachments": true,
      "options": {
        "temperature": 0.15,
        "top_p": 1
      }
    },
    {
      "id": "qwen3-4b",
      "name": "Venice Small",
      "cost_per_1m_in": 0.05,
      "cost_per_1m_out": 0.15,
      "cost_per_1m_in_cached": 0,
      "cost_per_1m_out_cached": 0,
      "context_window": 32768,
      "default_max_tokens": 8192,
      "can_reason": true,
      "reasoning_levels": [
        "low",
        "medium",
        "high"
      ],
      "default_reasoning_effort": "medium",
      "supports_attachments": false,
      "options": {
        "temperature": 0.6,
        "top_p": 0.95
      }
    }
  ]
}